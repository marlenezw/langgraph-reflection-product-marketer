{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Marketer with LangGraph and Responses API üõçÔ∏èüìù‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langgraph-reflection langchain openevals openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_reflection import create_reflection_graph\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from typing import TypedDict\n",
    "from openevals.llm import create_llm_as_judge\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-Vjy1VBTgmnNbmDu6e9cPaT\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def create_file(client, file_path):\n",
    "    if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "        # Download the file content from the URL\n",
    "        response = requests.get(file_path)\n",
    "        file_content = BytesIO(response.content)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_tuple = (file_name, file_content)\n",
    "        result = client.files.create(\n",
    "            file=file_tuple,\n",
    "            purpose=\"assistants\"\n",
    "        )\n",
    "    else:\n",
    "        # Handle local file path\n",
    "        with open(file_path, \"rb\") as file_content:\n",
    "            result = client.files.create(\n",
    "                file=file_content,\n",
    "                purpose=\"assistants\"\n",
    "            )\n",
    "    print(result.id)\n",
    "    return result.id\n",
    "\n",
    "# Replace with your own file path or URL\n",
    "file_id = create_file(client, \"hiking_products.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_67dd3eba12f48191ab289a29335d40b9\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"knowledge_base\"\n",
    ")\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-Vjy1VBTgmnNbmDu6e9cPaT', created_at=1742552765, last_error=None, object='vector_store.file', status='completed', usage_bytes=32314, vector_store_id='vs_67dd3eba12f48191ab289a29335d40b9', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))], has_more=False, object='list', first_id='file-Vjy1VBTgmnNbmDu6e9cPaT', last_id='file-Vjy1VBTgmnNbmDu6e9cPaT')\n"
     ]
    }
   ],
   "source": [
    "result = client.vector_stores.files.list(\n",
    "    vector_store_id=vector_store.id\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "model = init_chat_model(model=\"openai:gpt-4o\", use_responses_api=True)\n",
    "\n",
    "openai_vector_store_ids = [\n",
    "    vector_store.id,  # your IDs here\n",
    "]\n",
    "\n",
    "tools = [{\"type\": \"web_search_preview\"}, \n",
    "         {\"type\": \"file_search\",\n",
    "        \"vector_store_ids\": openai_vector_store_ids}]\n",
    "\n",
    "llm_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "I'm on the marketing team for an ecommerce camping store called Contoso Outdoors.\n",
    "Write me a short article that advertises the tents and sleeping bags we have in the hiking products file.\n",
    "Make sure to name the specific products you include in the article. \n",
    "You should also look for the latest trends for camping in the summer in California. and include those\n",
    "in the article. make sure to cite the sources you used. \n",
    "You should also include trending places to camp in California and link to information about those places.\n",
    "The article should use a friendly and approachable tone.\n",
    "\"\"\"\n",
    "\n",
    "# article = llm_with_tools.invoke(f'{prompt}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main assistant model that will generate responses\n",
    "def call_model(state):\n",
    "    \"\"\"Process the user query with a large language model.\"\"\"\n",
    "\n",
    "    print('Creating your article... üìù')\n",
    "    \n",
    "    return {\"messages\": llm_with_tools.invoke(state[\"messages\"])}\n",
    "\n",
    "# Define a basic graph for the main assistant\n",
    "assistant_graph = (\n",
    "    StateGraph(MessagesState)\n",
    "    .add_node(call_model)\n",
    "    .add_edge(START, \"call_model\")\n",
    "    .add_edge(\"call_model\", END)\n",
    "    .compile()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Define the tool that the judge can use to indicate the response is acceptable\n",
    "class Finish(TypedDict):\n",
    "    \"\"\"Tool for the judge to indicate the response is acceptable.\"\"\"\n",
    "\n",
    "    finish: bool\n",
    "\n",
    "\n",
    "# Define a more detailed critique prompt with specific evaluation criteria\n",
    "critique_prompt = \"\"\"You are an expert judge evaluating AI responses. Your task is to critique the AI assistant's latest response in the conversation below.\n",
    "\n",
    "Evaluate the response based on these criteria:\n",
    "1. Accuracy - Is the information correct and factual?\n",
    "2. Completeness - Does it fully address the user's query?\n",
    "3. Clarity - Is the explanation clear and well-structured?\n",
    "4. Helpfulness - Does it provide actionable and useful information?\n",
    "5. Safety - Does it avoid harmful or inappropriate content?\n",
    "\n",
    "If the response meets ALL criteria satisfactorily, set pass to True.\n",
    "\n",
    "If you find ANY issues with the response, do NOT set pass to True. Instead, provide specific and constructive feedback in the comment key and set pass to False.\n",
    "\n",
    "Be detailed in your critique so the assistant can understand exactly how to improve.\n",
    "\n",
    "<response>\n",
    "{outputs}\n",
    "</response>\"\"\"\n",
    "\n",
    "\n",
    "# Define the judge function with a more robust evaluation approach\n",
    "def judge_response(state, config):\n",
    "    \"\"\"Evaluate the assistant's response using a separate judge model.\"\"\"\n",
    "    evaluator = create_llm_as_judge(\n",
    "        prompt=critique_prompt,\n",
    "        model=\"openai:o3-mini\",\n",
    "        feedback_key=\"pass\",\n",
    "    )\n",
    "\n",
    "    print('Evaluating the article... üßê')\n",
    "    eval_result = evaluator(outputs=state[\"messages\"][-1].content, inputs=None)\n",
    "\n",
    "    if eval_result[\"score\"]:\n",
    "        print(\"‚úÖ Response approved by editor\")\n",
    "        print(\"\")\n",
    "        print(\"Here's your article:\")\n",
    "        \n",
    "        # Render and display as Markdown\n",
    "        display(Markdown(state[\"messages\"][-1].text()))\n",
    "        # print(state[\"messages\"][-1].text())\n",
    "        return\n",
    "    else:\n",
    "        # Otherwise, return the judge's critique as a new user message\n",
    "        print(\"‚ö†Ô∏è Judge requested improvements\")\n",
    "        return {\"messages\": [{\"role\": \"user\", \"content\": eval_result[\"comment\"]}]}\n",
    "\n",
    "\n",
    "# Define the judge graph\n",
    "judge_graph = (\n",
    "    StateGraph(MessagesState)\n",
    "    .add_node(judge_response)\n",
    "    .add_edge(START, \"judge_response\")\n",
    "    .add_edge(\"judge_response\", END)\n",
    "    .compile()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Content Generator and Editor with Reflection\n",
      "\n",
      "Creating your article... üìù\n",
      "Evaluating the article... üßê\n",
      "‚úÖ Response approved by editor\n",
      "\n",
      "Here's your article:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "As summer approaches, it's the perfect time to gear up for unforgettable camping adventures in California's breathtaking landscapes. At Contoso Outdoors, we offer top-quality tents and sleeping bags to ensure your comfort and safety under the stars.\n",
       "\n",
       "**Tents:**\n",
       "\n",
       "- **TrailMaster X4 Tent**: Designed for four occupants, this durable polyester tent features a water-resistant construction and a rainfly for added protection. Mesh panels provide ventilation and bug defense, while multiple doors and interior pockets enhance accessibility and organization. Reflective guy lines improve nighttime visibility, and its freestanding design allows for easy setup and relocation.\n",
       "\n",
       "- **SkyView 2-Person Tent**: Ideal for couples or solo campers, this tent offers a spacious interior with room to spare. Made from durable waterproof materials, it includes mesh panels for effective ventilation and comes with a rainfly for extra weather protection. Two large doors allow for easy access, and interior pockets help keep your gear organized.\n",
       "\n",
       "**Sleeping Bags:**\n",
       "\n",
       "- **MountainDream Sleeping Bag**: This 3-season sleeping bag is equipped with premium synthetic insulation, keeping you cozy even when temperatures drop to 15¬∞F. It features a durable water-resistant nylon shell, a soft breathable polyester lining, and a contoured mummy shape for optimal heat retention. Additional features include a snag-free YKK zipper, adjustable hood, and an interior pocket for essentials.\n",
       "\n",
       "- **CozyNights Sleeping Bag**: Lightweight and designed for spring, summer, and fall, this sleeping bag offers comfort and warmth. It includes a handy hood, ample room and padding, and a reliable temperature rating. Crafted from high-quality polyester, it ensures long-lasting use and can be zipped together with another bag for shared comfort.\n",
       "\n",
       "**Trending Camping Experiences in California:**\n",
       "\n",
       "Camping trends are evolving, with more people seeking unique and comfortable outdoor experiences. Glamping, or luxury camping, combines the escapism of nature with modern-day amenities, offering comfortable beds, access to Wi-Fi, and gourmet meals. Eco-friendly camping emphasizes environmental stewardship, encouraging campers to leave no trace and use sustainable products. Wellness camping focuses on activities like hiking, yoga, and meditation to improve overall health. ([cheapoair.com](https://www.cheapoair.com/miles-away/top-five-summer-camping-spots/?utm_source=openai))\n",
       "\n",
       "**Popular Camping Destinations in California:**\n",
       "\n",
       "California boasts numerous stunning camping spots. Here are a few to consider:\n",
       "\n",
       "- **Half Moon Bay State Beach**: Located on the bluffs overlooking the ocean, this campground offers 51 sites with beachfront views. It's a popular destination during the summer and shoulder seasons. ([sfchronicle.com](https://www.sfchronicle.com/outdoors/article/popular-campgrounds-california-2023-18611078.php?utm_source=openai))\n",
       "\n",
       "- **Yosemite National Park**: Home to 13 campgrounds, Yosemite offers opportunities to experience the state's exquisite flora and fauna, including awe-inspiring sequoias and noble bighorn sheep. ([cheapoair.com](https://www.cheapoair.com/miles-away/top-five-summer-camping-spots/?utm_source=openai))\n",
       "\n",
       "- **Ojai Valley**: Resting at the foot of Los Padres National Forest, Ojai Valley is home to several world-renowned spas and wellness centers, making it an ideal spot for wellness camping. ([cheapoair.com](https://www.cheapoair.com/miles-away/top-five-summer-camping-spots/?utm_source=openai))\n",
       "\n",
       "Before planning your trip, be sure to check the latest information and reservation details for these campgrounds.\n",
       "\n",
       "Equip yourself with Contoso Outdoors' premium gear and embrace the latest camping trends to make the most of California's summer camping season. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the complete reflection graph\n",
    "reflection_app = create_reflection_graph(assistant_graph, judge_graph)\n",
    "reflection_app = reflection_app.compile()\n",
    "\n",
    "\n",
    "\n",
    "# Example query that might need improvement\n",
    "example_query = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{prompt}\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Process the query through the reflection system\n",
    "print(\"Running Content Generator and Editor with Reflection\")\n",
    "print(\"\")\n",
    "result = reflection_app.invoke({\"messages\": example_query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
